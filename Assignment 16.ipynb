{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfab4b6",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405b16c",
   "metadata": {},
   "source": [
    "\n",
    "Web scraping is the automated process of extracting information, data, or content from websites. It involves writing code or using tools to access and retrieve data from web pages, which can then be stored, analyzed, or used for various purposes. Web scraping is commonly used to gather data that is not easily accessible through APIs or other means of data retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6525580",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e12d39",
   "metadata": {},
   "source": [
    "Beautiful Soup: Beautiful Soup is a Python library that provides tools for parsing HTML and XML documents. It allows you to navigate and manipulate the document's elements, making it easier to extract specific data. Beautiful Soup is commonly used in combination with requests, a library for making HTTP requests.\n",
    "\n",
    "APIs: While not traditional web scraping, many websites offer Application Programming Interfaces (APIs) that provide structured data in a more accessible format. Using APIs is generally more reliable and efficient than scraping the raw HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78155879",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535fa3d",
   "metadata": {},
   "source": [
    " Beautiful Soup is a Python library that provides tools for parsing HTML and XML documents. It allows you to navigate and manipulate the document's elements, making it easier to extract specific data. Beautiful Soup is commonly used in combination with requests, a library for making HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143e6a8",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a006a55b",
   "metadata": {},
   "source": [
    "flask is used to create an environment n which we can create an API to get data either through GET or POST method  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11080b94",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68824a",
   "metadata": {},
   "source": [
    "The services we used in the project were : Elastic Beanstack and Code pipeline\n",
    "\n",
    "Elastic beanstact is used to create an environment on which our project is deployed where as code pipeline holds the code which is to be deployed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c7f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
